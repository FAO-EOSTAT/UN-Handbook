<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Gilberto Camara, Lorenzo de Simone, Ronald Jansen">
<title>14&nbsp; Crop classification in Mexico – UN Handbook on Remote Sensing for Agricultural Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ct_senegal.html" rel="next">
<link href="./ct_poland.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-931bd9de4a2e97c797357f31cd37fa94.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./crop_type_mapping.html">Use Cases in Crop Type Mapping</a></li><li class="breadcrumb-item"><a href="./ct_mexico.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Crop classification in Mexico</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">UN Handbook on Remote Sensing for Agricultural Statistics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/FAO-EOSTAT/UN-Handbook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Welcome</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./howto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">How to use this handbook</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_remote_sensing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Remote Sensing images: optical, SAR</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_lucc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Land cover and crop classification schemas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_quality_control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Quality control of training sets for agricultural statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Machine learning classification of remote sensing images</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Spatial map uncertainty estimation and active learning in crop classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Map validation and use of maps for area estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">EO Big Data Sources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_design_frames.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Remote Sensing in the Design of Sampling Frames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_parcel_extraction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Automatic Extraction of Parcels</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./crop_type_mapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Use Cases in Crop Type Mapping</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_poland.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Crop monitoring with SAR images in Poland</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_mexico.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Crop classification in Mexico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_senegal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Multi-seasonal crop mapping in Senegal</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_zimbabwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Crop classification in Zimbabwe</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_chile.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Crop classification and land use mapping in Chile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_digital_earth_africa.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Crop classification using Digital Earth Africa</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./crop_yield_estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Crop yield estimation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_finland.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Early-season crop yield mapping in Finland</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_indonesia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Mapping crop phenology in Indonesia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_poland.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Yield Forecasting in Poland</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_colombia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Rice Phenology in Colombia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_china.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Crop type classification and crop yield estimation in China</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./additional.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Additional Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_geoglam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Extraction of crop statistics from crop type and crop yield maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_world_cereal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">WorldCereal - A Global Effort for Crop Mapping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_uav_applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">UAV use in Agricultural Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_disaster_response.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Remote Sensing for Agricultural Disaster Response</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_governance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Data Governance for Agricultural Statistics</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#outline" id="toc-outline" class="nav-link active" data-scroll-target="#outline"><span class="header-section-number">14.1</span> Outline</a></li>
  <li>
<a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods"><span class="header-section-number">14.2</span> Methods</a>
  <ul class="collapse">
<li><a href="#study-area-and-datasets" id="toc-study-area-and-datasets" class="nav-link" data-scroll-target="#study-area-and-datasets"><span class="header-section-number">14.2.1</span> Study Area and datasets</a></li>
  <li><a href="#image-segmentation-for-parcel-delineation" id="toc-image-segmentation-for-parcel-delineation" class="nav-link" data-scroll-target="#image-segmentation-for-parcel-delineation"><span class="header-section-number">14.2.2</span> Image segmentation for parcel delineation</a></li>
  <li><a href="#ground-truth-labeling-and-quality-control" id="toc-ground-truth-labeling-and-quality-control" class="nav-link" data-scroll-target="#ground-truth-labeling-and-quality-control"><span class="header-section-number">14.2.3</span> Ground-Truth labeling and quality control</a></li>
  <li><a href="#time-series-feature-engineering" id="toc-time-series-feature-engineering" class="nav-link" data-scroll-target="#time-series-feature-engineering"><span class="header-section-number">14.2.4</span> Time-Series Feature Engineering</a></li>
  <li><a href="#machine-learning-modeling" id="toc-machine-learning-modeling" class="nav-link" data-scroll-target="#machine-learning-modeling"><span class="header-section-number">14.2.5</span> Machine Learning Modeling</a></li>
  </ul>
</li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">14.3</span> Results</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="header-section-number">14.4</span> Discussion</a></li>
  <li><a href="#conclusion-and-future-work" id="toc-conclusion-and-future-work" class="nav-link" data-scroll-target="#conclusion-and-future-work"><span class="header-section-number">14.5</span> Conclusion and future work</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/FAO-EOSTAT/UN-Handbook/edit/quarto/ct_mexico.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/FAO-EOSTAT/UN-Handbook/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./crop_type_mapping.html">Use Cases in Crop Type Mapping</a></li><li class="breadcrumb-item"><a href="./ct_mexico.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Crop classification in Mexico</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Crop classification in Mexico</span>
</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Abel Coronado </p>
          </div>
  </div>
    
  
    
  </div>
  


</header><section id="outline" class="level2" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="outline">
<span class="header-section-number">14.1</span> Outline</h2>
<p>This chapter contributes to the handbook’s goal of enhancing the operational use of Earth Observation (EO) in agricultural statistics by presenting a detailed, step-by-step classification exercise. While the potential of remote sensing is widely recognized, many National Statistical Offices (NSOs) still face challenges in transforming satellite data into reliable statistical products. To address this, we provide a didactic case study focused on crop classification in Mexico, designed to be fully reproducible by the user.</p>
<p>The exercise centers on the Yaqui Valley, a prominent agricultural region in Sonora, Mexico. The primary analysis period covers the autumn-winter agricultural season from October 2017 to May 2018. The workflow is built upon an Object-Based Image Analysis (OBIA) approach <span class="citation" data-cites="Blaschke2010 Dezso2012"><a href="#ref-Blaschke2010" role="doc-biblioref">[1]</a>, <a href="#ref-Dezso2012" role="doc-biblioref">[2]</a></span>, where machine learning models are trained to classify agricultural parcels rather than individual pixels. This method often yields more accurate and coherent results that better represent real-world field conditions.</p>
<p>The methodology leverages a fusion of open-access optical and radar satellite data <span class="citation" data-cites="Orynbaikyzy2019"><a href="#ref-Orynbaikyzy2019" role="doc-biblioref">[3]</a></span>. We use the Harmonized Landsat and Sentinel-2 (HLS) product <span class="citation" data-cites="Junchang2025 Junchang2022"><a href="#ref-Junchang2025" role="doc-biblioref">[4]</a>, <a href="#ref-Junchang2022" role="doc-biblioref">[5]</a></span>, which provides analysis-ready, radiometrically consistent surface reflectance data, along with Sentinel-1 SAR imagery <span class="citation" data-cites="Shorachi2022"><a href="#ref-Shorachi2022" role="doc-biblioref">[6]</a></span> to ensure data availability regardless of cloud cover. To facilitate the didactic and reproducible nature of this chapter, all necessary components—the pre-processed satellite imagery, the ground-truth labels used for training, and the complete Python code—are made available for download from a public repository. This allows the reader to focus entirely on understanding and replicating the classification process itself.</p>
</section><section id="methods" class="level2" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="methods">
<span class="header-section-number">14.2</span> Methods</h2>
<p>This section details the complete, step-by-step workflow for the crop classification exercise, from the initial data description to the final machine learning modeling.</p>
<section id="study-area-and-datasets" class="level3" data-number="14.2.1"><h3 data-number="14.2.1" class="anchored" data-anchor-id="study-area-and-datasets">
<span class="header-section-number">14.2.1</span> Study Area and datasets</h3>
<p>The methodology is demonstrated in the Yaqui Valley, located in the state of Sonora, Mexico. This area is one of the nation’s most productive agricultural regions, characterized by intensive, irrigated cultivation of crops such as wheat, corn, and vegetables, making it an ideal case study for classification techniques.</p>
<p>To ensure the exercise is fully reproducible, all required datasets are provided. The analysis relies on a fusion of publicly available optical and radar imagery covering the agricultural season from October 2017 to May 2018. The datasets include:</p>
<ul>
<li><p>Optical Time-Series: A set of monthly, cloud-free composite images derived from the Harmonized Landsat and Sentinel-2 (HLS) collection <span class="citation" data-cites="Junchang2025"><a href="#ref-Junchang2022" role="doc-biblioref">[5]</a></span>. Additionally, a single geometric median composite of the entire period is provided, which serves as the primary layer for image segmentation. Each image contains 13 bands, including surface reflectance and a suite of vegetation indices.</p></li>
<li><p>Radar Time-Series: A corresponding monthly time-series of Sentinel-1 Ground Range Detected (GRD) imagery <span class="citation" data-cites="Shorachi2022"><a href="#ref-Shorachi2022" role="doc-biblioref">[6]</a></span>. Each monthly composite includes bands for VV and VH backscatter, as well as the calculated Radar Vegetation Index (RVI).</p></li>
<li><p>Ground-Truth Data: A shapefile containing georeferenced sample points used for training and validating the models. This information is derived from administrative records of the Agrifood and Fisheries Information Service (SIAP) of Mexico <span class="citation" data-cites="GeospatialWorld2014"><a href="#ref-GeospatialWorld2014" role="doc-biblioref">[7]</a></span>.</p></li>
</ul></section><section id="image-segmentation-for-parcel-delineation" class="level3" data-number="14.2.2"><h3 data-number="14.2.2" class="anchored" data-anchor-id="image-segmentation-for-parcel-delineation">
<span class="header-section-number">14.2.2</span> Image segmentation for parcel delineation</h3>
<p>The first step in our analytical workflow is to transition from a pixel-based to an Object-Based Image Analysis (OBIA) approach. This process, known as image segmentation, aggregates pixels into homogeneous regions that are intended to correspond to real-world features. For this agricultural application, the fundamental unit of analysis is shifted from the individual pixel to the image object or segment, which represents a potential agricultural parcel.</p>
<p>For this task, the Shepherd Segmentation algorithm from the RSGISLib library was employed <span class="citation" data-cites="Clewley2014"><a href="#ref-Clewley2014" role="doc-biblioref">[8]</a></span>. This algorithm was applied to the high-quality, multi-band geometric median composite described previously. The method is a two-stage process: it first uses a k-means clustering to group pixels based on their spectral similarity, and then iteratively merges these small clusters into larger, spatially contiguous segments. Key parameters used in this process were:</p>
<ul>
<li>Number of Clusters: The process was initialized with 80 spectral clusters to capture the initial variability.</li>
<li>Input Bands: All 13 bands of the composite image (six optical and seven vegetation indices) were used, providing a rich spectral basis for clustering.</li>
<li>Minimum Segment Size: A minimum size of 100 pixels was enforced to eliminate small, noisy polygons and ensure that the final objects are representative of field parcels.</li>
</ul>
<p>The final output of this step is a vector shapefile containing the delineated polygons. It is important to acknowledge that as an automated process, the segmentation may not perfectly align with all real-world field boundaries, and some inaccuracies from under- or over-segmentation can occur, particularly in complex landscapes. Nevertheless, these generated objects form the foundational units for all subsequent labeling and feature extraction steps.</p>
</section><section id="ground-truth-labeling-and-quality-control" class="level3" data-number="14.2.3"><h3 data-number="14.2.3" class="anchored" data-anchor-id="ground-truth-labeling-and-quality-control">
<span class="header-section-number">14.2.3</span> Ground-Truth labeling and quality control</h3>
<p>Once the agricultural parcels were delineated, the next critical step was to assign a known crop type to each segment using the ground-truth data. This was achieved through a spatial join <span class="citation" data-cites="Longley2015"><a href="#ref-Longley2015" role="doc-biblioref">[9]</a></span>, a standard GIS operation that overlays the georeferenced sample points derived from SIAP administrative records onto the polygon layer. This process transfers the crop label from each point to the larger parcel segment that contains it.</p>
<p>However, an initial join can result in ambiguity; a single polygon might intersect with points corresponding to multiple different crop types, or with no points at all. To create a reliable dataset for model training, a strict quality control filter was therefore applied to the joined data. The rule for this filter was to retain only those polygons that were unambiguously labeled—that is, polygons that contained sample points corresponding to one, and only one, unique crop type.</p>
<p>This filtering protocol is crucial for improving the purity of the training data. Any polygon that contained no sample points (unlabeled) or was associated with conflicting crop labels (ambiguously labeled) was discarded from the final dataset. The output of this stage is a clean shapefile of high-confidence parcels, each with a single, verified class label, which serves as the definitive ground truth for the subsequent feature extraction and modeling phases.</p>
</section><section id="time-series-feature-engineering" class="level3" data-number="14.2.4"><h3 data-number="14.2.4" class="anchored" data-anchor-id="time-series-feature-engineering">
<span class="header-section-number">14.2.4</span> Time-Series Feature Engineering</h3>
<p>The final data preparation step involves feature engineering, where a comprehensive set of quantitative attributes is generated for each delineated parcel. This feature set is designed to capture the unique temporal and spectral signatures of each crop type, which the machine learning model will use to perform the classification. The central data structure for this process is the Raster Attribute Table (RAT) associated with the segmentation file, which is progressively populated with new attributes.</p>
<p>The process is executed using the zonal statistics <span class="citation" data-cites="Winsemius2024"><a href="#ref-Winsemius2024" role="doc-biblioref">[10]</a></span> capabilities of the <code>rsgislib</code> library. First, the RAT is populated with class proportion information derived from the ground-truth labels raster. This initial step calculates, for each segment, the percentage of its area corresponding to each crop class.</p>
<p>Subsequently, the RAT is further enriched with a much larger set of features derived from the entire time-series of satellite imagery. For <em>each band</em> of <em>every monthly composite</em>—both the optical HLS and radar Sentinel-1 images—a set of descriptive statistics is computed for each parcel. These statistics include the mean, standard deviation, minimum, and maximum pixel values within the parcel’s boundary.</p>
<p>The result of this stage is a highly detailed data table within the RAT, where each row represents a single parcel and the columns contain its complete phenological and structural profile. This profile captures not only the average spectral response of the parcel over time (the mean values) but also its internal heterogeneity or texture (the standard deviation). This final feature table is then exported as a CSV file, creating the analysis-ready dataset for the machine learning workflow.</p>
</section><section id="machine-learning-modeling" class="level3" data-number="14.2.5"><h3 data-number="14.2.5" class="anchored" data-anchor-id="machine-learning-modeling">
<span class="header-section-number">14.2.5</span> Machine Learning Modeling</h3>
<p>The final stage of the methodology focuses on training and selecting the optimal classification model using the comprehensive feature set generated in the previous steps. To streamline this process, this exercise utilizes <code>PyCaret</code> <span class="citation" data-cites="Ali2020"><a href="#ref-Ali2020" role="doc-biblioref">[11]</a></span>, an open-source, low-code Automated Machine Learning (AutoML) library in Python. <code>PyCaret</code> was chosen for its ability to efficiently automate the entire experimental workflow, from data preprocessing to model comparison and selection.</p>
<p>Before initiating the AutoML experiment, two critical data preparation steps were performed. First, to address the severe class imbalance in the dataset, any crop class with fewer than 10 representative samples was aggregated into a single ‘Grouped Minorities’ category. This pragmatic approach creates a more stable class distribution for the models to learn from. Second, the dataset was partitioned into a 70% training set and a 30% testing set using stratified sampling. This ensures that the proportional representation of each class is preserved in both subsets, which is crucial for obtaining an unbiased evaluation of model performance.</p>
<p>The <code>PyCaret</code> <code>setup()</code> function was then used to configure the experiment, establishing a pipeline of automated preprocessing steps that are applied during model training and evaluation. This included robust feature scaling, automated feature selection to identify the 50 most predictive variables from the high-dimensional dataset, and an additional balancing technique (<code>RandomOverSampler</code>) <span class="citation" data-cites="Chawla2002"><a href="#ref-Crudu2025" role="doc-biblioref">[13]</a></span> applied to the training folds within the cross-validation loop. Model performance was evaluated using a 5-fold stratified cross-validation strategy to ensure robust and reliable results.</p>
<p>Finally, the <code>compare_models()</code> function was executed to systematically train and evaluate a wide range of classification algorithms. The results identified the Extreme Gradient Boosting (XGBoost) <span class="citation" data-cites="Chen2016"><a href="#ref-Chen2016" role="doc-biblioref">[14]</a></span> model as the top performer, achieving the highest cross-validated accuracy of 89.5%. This winning model, along with its complete preprocessing pipeline, was then saved for generating the final results presented in the following section.</p>
</section></section><section id="results" class="level2" data-number="14.3"><h2 data-number="14.3" class="anchored" data-anchor-id="results">
<span class="header-section-number">14.3</span> Results</h2>
<p>This section presents the performance of the final classification model, Extreme Gradient Boosting (XGBoost), on the independent test set. The model yielded an overall accuracy of 89.5%.</p>
<p>A detailed breakdown of the model’s performance is provided in the classification report (<a href="#tbl-classreport-mexico" class="quarto-xref">Table&nbsp;<span>14.1</span></a>). The weighted average F1-score, which accounts for class imbalance, was 0.896. The results show a performance disparity between classes. The model achieved high recall scores for majority classes such as Wheat (94.9%) and Other Veg/Water (98.8%), while recall was significantly lower for minority classes, including the Grouped Minorities category (4.5%).</p>
<div id="tbl-classreport-mexico" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-classreport-mexico-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;14.1: Per-class classification report for the XGBoost model on the test set, ordered by recall (descending)
</figcaption><div aria-describedby="tbl-classreport-mexico-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead><tr class="header">
<th>Class Name</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1-Score</th>
<th style="text-align: center;">Support</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Other Veg/Water</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.988</td>
<td style="text-align: center;">0.983</td>
<td style="text-align: center;">494</td>
</tr>
<tr class="even">
<td>Wheat</td>
<td style="text-align: center;">0.941</td>
<td style="text-align: center;">0.949</td>
<td style="text-align: center;">0.945</td>
<td style="text-align: center;">1509</td>
</tr>
<tr class="odd">
<td>Chickpea</td>
<td style="text-align: center;">0.777</td>
<td style="text-align: center;">0.880</td>
<td style="text-align: center;">0.826</td>
<td style="text-align: center;">234</td>
</tr>
<tr class="even">
<td>Corn</td>
<td style="text-align: center;">0.870</td>
<td style="text-align: center;">0.812</td>
<td style="text-align: center;">0.840</td>
<td style="text-align: center;">271</td>
</tr>
<tr class="odd">
<td>Alfalfa</td>
<td style="text-align: center;">0.842</td>
<td style="text-align: center;">0.762</td>
<td style="text-align: center;">0.800</td>
<td style="text-align: center;">21</td>
</tr>
<tr class="even">
<td>Tomato</td>
<td style="text-align: center;">0.604</td>
<td style="text-align: center;">0.744</td>
<td style="text-align: center;">0.667</td>
<td style="text-align: center;">43</td>
</tr>
<tr class="odd">
<td>Bean</td>
<td style="text-align: center;">0.711</td>
<td style="text-align: center;">0.696</td>
<td style="text-align: center;">0.703</td>
<td style="text-align: center;">46</td>
</tr>
<tr class="even">
<td>Potato</td>
<td style="text-align: center;">0.571</td>
<td style="text-align: center;">0.462</td>
<td style="text-align: center;">0.511</td>
<td style="text-align: center;">52</td>
</tr>
<tr class="odd">
<td>Chile Pepper</td>
<td style="text-align: center;">0.500</td>
<td style="text-align: center;">0.455</td>
<td style="text-align: center;">0.476</td>
<td style="text-align: center;">11</td>
</tr>
<tr class="even">
<td>Squash</td>
<td style="text-align: center;">0.486</td>
<td style="text-align: center;">0.429</td>
<td style="text-align: center;">0.456</td>
<td style="text-align: center;">42</td>
</tr>
<tr class="odd">
<td>Asparagus</td>
<td style="text-align: center;">0.750</td>
<td style="text-align: center;">0.333</td>
<td style="text-align: center;">0.462</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="even">
<td>Grouped Minorities</td>
<td style="text-align: center;">0.200</td>
<td style="text-align: center;">0.045</td>
<td style="text-align: center;">0.074</td>
<td style="text-align: center;">22</td>
</tr>
<tr class="odd">
<td>Weighted Avg</td>
<td style="text-align: center;">0.895</td>
<td style="text-align: center;">0.899</td>
<td style="text-align: center;">0.896</td>
<td style="text-align: center;">2754</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>To visually assess the model’s behavior, the normalized confusion matrix is presented in <a href="#fig-confusionmatrix-mexico" class="quarto-xref">Figure&nbsp;<span>14.1</span></a>. The strong diagonal, with recall values of <strong>98.8% for Other Veg/Water</strong> and <strong>94.9% for Wheat</strong>, confirms the model’s high accuracy for the majority classes. However, the off-diagonal values highlight specific areas of confusion. For instance, <strong>Potato</strong> is frequently misclassified as <strong>Corn</strong> (36.5% of the time), and a notable portion of <strong>Onion</strong> samples are also confused with Corn (19.6%). This suggests that these crops may share similar spectral profiles at certain growth stages within the analyzed period. As expected, the model struggles most with the <strong>Grouped Minorities</strong> class, which has a recall of only 4.5% and is primarily confused with the dominant Wheat and Other Veg/Water classes.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-confusionmatrix-mexico" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-confusionmatrix-mexico-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/ct_mexico/image_f687c5.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-confusionmatrix-mexico-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.1: Normalized confusion matrix (Recall) of the XGBoost model on the test set. The diagonal shows the percentage of correctly classified parcels for each class
</figcaption></figure>
</div>
</div>
</div>
<p>Finally, the trained model can be applied to all delineated parcels in the study area to produce the final crop classification map for the 2017-2018 agricultural season (an example is shown in <a href="#fig-classificationmap-mexico" class="quarto-xref">Figure&nbsp;<span>14.2</span></a>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-classificationmap-mexico" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-classificationmap-mexico-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/ct_mexico/final_map.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-classificationmap-mexico-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.2: Crop type classification map for the Yaqui Valley study area.
</figcaption></figure>
</div>
</div>
</div>
</section><section id="discussion" class="level2" data-number="14.4"><h2 data-number="14.4" class="anchored" data-anchor-id="discussion">
<span class="header-section-number">14.4</span> Discussion</h2>
<p>The application of a combined optical-radar, object-based approach with an XGBoost model yielded an overall accuracy of 89.5% on the independent test set. The model’s recall for majority classes, such as Wheat (94.9%) and Other Veg/Water (98.8%), corresponds to their distinct spectral signatures and the large number of available training samples.</p>
<p>In contrast, the model’s performance was lower for classes with fewer training samples. The detailed classification report (<a href="#tbl-classreport-mexico" class="quarto-xref">Table&nbsp;<span>14.1</span></a>) shows recall values of 33.3% for Asparagus and 4.5% for the aggregated Grouped Minorities category. This performance gap is directly related to the class imbalance in the training data. An insufficient number of examples can limit a model’s ability to learn a generalizable signature for minority classes, potentially leading to a bias towards better-represented classes.</p>
<p>The confusion matrix (<a href="#fig-confusionmatrix-mexico" class="quarto-xref">Figure&nbsp;<span>14.1</span></a>) provides further detail on specific inter-class confusion. For example, a portion of Potato parcels were misclassified as Corn. A possible explanation for this is that these crops may share similar phenological profiles or spectral characteristics during key moments of the analyzed growing season. This represents a classification challenge that is both statistical and agronomic in nature.</p>
<p>From a practical standpoint for National Statistical Offices (NSOs), the open-source workflow presented here offers a methodology for mapping dominant crops, which are often of primary interest for food security monitoring. The results from this exercise also underscore that the quality, quantity, and balance of ground-truth data are determining factors that influence the performance of supervised classification models.</p>
</section><section id="conclusion-and-future-work" class="level2" data-number="14.5"><h2 data-number="14.5" class="anchored" data-anchor-id="conclusion-and-future-work">
<span class="header-section-number">14.5</span> Conclusion and future work</h2>
<p>This chapter presented a reproducible, open-source workflow for crop classification in a major agricultural region of Mexico. The methodology, which combines an object-based approach with an XGBoost model trained on multi-sensor time-series features, yielded an overall accuracy of 89.5% for mapping dominant crops. A key observation from the results is that model performance is influenced by the quality and class balance of the ground-truth data, as shown by the lower recall values for minority crop types.</p>
<p>The current results can serve as a baseline for further research. One direction for future work is to explore deep learning architectures capable of learning directly from temporal data, as an alternative to relying on pre-computed statistical features. The preliminary experiments conducted as part of this study indicate potential research directions in this area.</p>
<p>One avenue for investigation is the use of 1D Convolutional Neural Networks (1D-CNNs) <span class="citation" data-cites="Guessoum2022"><a href="#ref-Guessoum2022" role="doc-biblioref">[15]</a></span> to automatically extract features from sequential data like vegetation index time-series. A further area for investigation is the fusion of optical and radar data within the deep learning model structure itself. A different approach is to develop dual-input hybrid models <span class="citation" data-cites="Saidi2024"><a href="#ref-Saidi2024" role="doc-biblioref">[16]</a></span>. Such an architecture can process temporal data through a 1D-CNN or LSTM branch while simultaneously processing static, season-long features through a parallel MLP branch, allowing the model to learn from both dynamic and stable parcel characteristics. A systematic evaluation of these deep learning approaches could determine their potential to increase classification accuracy for NSO applications.</p>
</section><section id="references" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-Blaschke2010" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div>
<div class="csl-right-inline">T. Blaschke, <span>“Object based image analysis for remote sensing,”</span> <em>{ISPRS} Journal of Photogrammetry and Remote Sensing</em>, vol. 65, no. 1, pp. 2–16, 2010.</div>
</div>
<div id="ref-Dezso2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div>
<div class="csl-right-inline">B. Dezso <em>et al.</em>, <span>“Object-based image analysis in remote sensing applications using various segmentation techniques,”</span> vol. 37, pp. 103–120, 2012.</div>
</div>
<div id="ref-Orynbaikyzy2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div>
<div class="csl-right-inline">A. Orynbaikyzy, U. Gessner, and C. Conrad, <span>“Crop type classification using a combination of optical and radar remote sensing data: A review,”</span> <em>International Journal of Remote Sensing</em>, vol. 40, no. 3, pp. 1–43, 2019, doi: <a href="https://doi.org/10.1080/01431161.2019.1569791">10.1080/01431161.2019.1569791</a>.</div>
</div>
<div id="ref-Junchang2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div>
<div class="csl-right-inline">J. Ju <em>et al.</em>, <span>“The harmonized landsat and sentinel-2 version 2.0 surface reflectance dataset,”</span> <em>Remote Sensing of Environment</em>, vol. 324, p. 114723, 2025, doi: <a href="https://doi.org/10.1016/j.rse.2025.114723">10.1016/j.rse.2025.114723</a>.</div>
</div>
<div id="ref-Junchang2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div>
<div class="csl-right-inline">J. Ju <em>et al.</em>, <em><a href="https://lpdaac.usgs.gov/documents/1698/HLS_User_Guide_V2.pdf">Harmonized landsat sentinel-2 (HLS) product user guide</a></em>. NASA/USGS, 2022.</div>
</div>
<div id="ref-Shorachi2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div>
<div class="csl-right-inline">M. Shorachi, V. Kumar, and S. C. Steele-Dunne, <span>“Sentinel-1 SAR backscatter response to agricultural drought in the netherlands,”</span> <em>Remote Sensing</em>, vol. 14, no. 10, p. 2435, 2022, doi: <a href="https://doi.org/10.3390/rs14102435">10.3390/rs14102435</a>.</div>
</div>
<div id="ref-GeospatialWorld2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div>
<div class="csl-right-inline">Geospatial World, <span>“The geospatial technology in the agrifood and fisheries information service (SIAP), méxico,”</span> 2014, [Online]. Available: <a href="https://geospatialworld.net/article/the-geospatial-technology-in-the-agrifood-and-fisheries-information-service-siap-mexico/">https://geospatialworld.net/article/the-geospatial-technology-in-the-agrifood-and-fisheries-information-service-siap-mexico/</a>.</div>
</div>
<div id="ref-Clewley2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div>
<div class="csl-right-inline">D. Clewley <em>et al.</em>, <span>“A python-based open source system for geographic object-based image analysis (GEOBIA) utilizing raster attribute tables,”</span> <em>Remote Sensing</em>, vol. 6, no. 7, pp. 6111–6135, 2014, doi: <a href="https://doi.org/10.3390/rs6076111">10.3390/rs6076111</a>.</div>
</div>
<div id="ref-Longley2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div>
<div class="csl-right-inline">P. A. Longley, M. F. Goodchild, D. J. Maguire, and D. W. Rhind, <em>Geographic information science and systems</em>. John Wiley &amp; Sons, 2015.</div>
</div>
<div id="ref-Winsemius2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div>
<div class="csl-right-inline">S. Winsemius and J. Braaten, <span>“<a href="https://doi.org/10.1007/978-3-031-26588-4_24">Zonal statistics</a>,”</span> in <em>Cloud-based remote sensing with google earth engine</em>, Springer, 2024, pp. 463–485.</div>
</div>
<div id="ref-Ali2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div>
<div class="csl-right-inline">M. Ali, <span>“PyCaret: An open source, low-code machine learning library in python.”</span> <a href="https://pycaret.readthedocs.io/en/latest/" class="uri">https://pycaret.readthedocs.io/en/latest/</a>, 2020, [Online]. Available: <a href="https://www.pycaret.org">https://www.pycaret.org</a>.</div>
</div>
<div id="ref-Chawla2002" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div>
<div class="csl-right-inline">N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, <span>“<span>SMOTE</span>: Synthetic minority over-sampling technique,”</span> <em>Journal of Artificial Intelligence Research</em>, vol. 16, no. 1, pp. 321–357, 2002.</div>
</div>
<div id="ref-Crudu2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div>
<div class="csl-right-inline">A. Crudu and MoldStud Research Team, <span>“Strategies and resources for successfully tackling class imbalance in classification challenges,”</span> <em>MoldStud Articles</em>, 2025, [Online]. Available: <a href="https://moldstud.com/articles/p-strategies-and-resources-for-successfully-tackling-class-imbalance-in-classification-challenges">https://moldstud.com/articles/p-strategies-and-resources-for-successfully-tackling-class-imbalance-in-classification-challenges</a>.</div>
</div>
<div id="ref-Chen2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div>
<div class="csl-right-inline">T. Chen and C. Guestrin, <span>“<span>XGBoost</span>: <span>A Scalable Tree Boosting System</span>,”</span> in <em>Proceedings of the 22nd <span>ACM SIGKDD International Conference</span> on <span>Knowledge Discovery</span> and <span>Data Mining</span></em>, 2016, pp. 785–794, doi: <a href="https://doi.org/10.1145/2939672.2939785">10.1145/2939672.2939785</a>.</div>
</div>
<div id="ref-Guessoum2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div>
<div class="csl-right-inline">S. Guessoum <em>et al.</em>, <span>“The short-term prediction of length of day using 1D convolutional neural networks (1D CNN),”</span> <em>Sensors</em>, vol. 22, no. 23, p. 9517, 2022, [Online]. Available: <a href="https://www.mdpi.com/1424-8220/22/23/9517">https://www.mdpi.com/1424-8220/22/23/9517</a>.</div>
</div>
<div id="ref-Saidi2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div>
<div class="csl-right-inline">S. Saidi, S. Idbraim, Y. Karmoude, A. Masse, and M. Arbelo, <span>“Deep-learning for change detection using multi-modal fusion of remote sensing images: A review,”</span> <em>Remote Sensing</em>, vol. 16, no. 20, p. 3852, 2024, doi: <a href="https://doi.org/10.3390/rs16203852">10.3390/rs16203852</a>.</div>
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/FAO-EOSTAT\.github\.io\/UN-Handbook\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./ct_poland.html" class="pagination-link" aria-label="Crop monitoring with SAR images in Poland">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Crop monitoring with SAR images in Poland</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ct_senegal.html" class="pagination-link" aria-label="Multi-seasonal crop mapping in Senegal">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Multi-seasonal crop mapping in Senegal</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Edited by Gilberto Camara, Lorenzo de Simone and Ronald Jansen.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/FAO-EOSTAT/UN-Handbook/edit/quarto/ct_mexico.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/FAO-EOSTAT/UN-Handbook/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>