<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Gilberto Camara, Lorenzo de Simone, Ronald Jansen">
<title>UN Handbook on Remote Sensing for Agricultural Statistics - 4&nbsp; Remote sensing images: optical, SAR</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./th_data_sources.html" rel="next">
<link href="./theory.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./theory.html">Foundations</a></li><li class="breadcrumb-item"><a href="./th_remote_sensing.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Remote sensing images: optical, SAR</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">UN Handbook on Remote Sensing for Agricultural Statistics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/FAO-EOSTAT/UN-Handbook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Welcome</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./howto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">How to use this handbook</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_remote_sensing.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Remote sensing images: optical, SAR</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_data_sources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Earth observation big data sources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_lucc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Land cover and crop classification schemas</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_quality_control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Quality control of training sets for agricultural statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Machine learning algorithms for image time series</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Spatial map uncertainty estimation and active learning in crop classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_validation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Map validation and use of maps for area estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_design_frames.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Remote Sensing in the Design of Sampling Frames</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./th_parcel_extraction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Automatic Extraction of Parcels</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./crop_type_mapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Use Cases in Crop Type Mapping</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_poland.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Crop monitoring with SAR images in Poland</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_mexico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Crop classification in Mexico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_senegal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Multi-seasonal crop mapping in Senegal</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_zimbabwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Crop classification in Zimbabwe</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_chile.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Crop classification and land use mapping in Chile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ct_digital_earth_africa.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Agricultural Mapping with Digital Earth Africa</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./crop_yield_estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Crop yield estimation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_finland.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Early-season crop yield mapping in Finland</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_indonesia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Mapping crop phenology in Indonesia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_poland.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Yield forecasting in Poland</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_colombia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Rice Phenology in Colombia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cy_china.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Crop type classification and crop yield estimation in China</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./additional.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Additional Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_geoglam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Extraction of crop statistics from crop type and crop yield maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_world_cereal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">WorldCereal - A Global Effort for Crop Mapping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_uav_applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">UAV use in Agricultural Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_disaster_response.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Remote Sensing for Agricultural Disaster Response</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ad_governance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Data Governance for Agricultural Statistics</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#outline" id="toc-outline" class="nav-link active" data-scroll-target="#outline"><span class="header-section-number">4.1</span> Outline</a></li>
  <li><a href="#introduction-of-remote-sensing-imagery" id="toc-introduction-of-remote-sensing-imagery" class="nav-link" data-scroll-target="#introduction-of-remote-sensing-imagery"><span class="header-section-number">4.2</span> Introduction of remote sensing imagery</a></li>
  <li><a href="#chinese-earth-observation-satellites" id="toc-chinese-earth-observation-satellites" class="nav-link" data-scroll-target="#chinese-earth-observation-satellites"><span class="header-section-number">4.3</span> Chinese Earth observation satellites</a></li>
  <li><a href="#landsat-programme" id="toc-landsat-programme" class="nav-link" data-scroll-target="#landsat-programme"><span class="header-section-number">4.4</span> Landsat programme</a></li>
  <li>
<a href="#copernicus-programme" id="toc-copernicus-programme" class="nav-link" data-scroll-target="#copernicus-programme"><span class="header-section-number">4.5</span> Copernicus Programme</a>
  <ul class="collapse">
<li><a href="#sentinel-1-mission" id="toc-sentinel-1-mission" class="nav-link" data-scroll-target="#sentinel-1-mission"><span class="header-section-number">4.5.1</span> Sentinel-1 mission</a></li>
  <li><a href="#sentinel-2-mission" id="toc-sentinel-2-mission" class="nav-link" data-scroll-target="#sentinel-2-mission"><span class="header-section-number">4.5.2</span> Sentinel-2 mission</a></li>
  </ul>
</li>
  <li><a href="#final-remarks" id="toc-final-remarks" class="nav-link" data-scroll-target="#final-remarks"><span class="header-section-number">4.6</span> Final remarks</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/FAO-EOSTAT/UN-Handbook/edit/quarto/th_remote_sensing.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/FAO-EOSTAT/UN-Handbook/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Remote sensing images: optical, SAR</span>
</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Pan Yaozhong </p>
          </div>
  </div>
    
  
    
  </div>
  

</header><section id="outline" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="outline">
<span class="header-section-number">4.1</span> Outline</h2>
<p>This chapter provides a general introduction to remote sensing imagery. The authors discuss different types of remote sensing satellites (optical, SAR, hyperspectral) and include examples of satellite constellations (e.g, Landsat, Copernicus, CHEOS). The chapter describes the main characteristics of various Earth observation satellites. For a description of how to access satellites from the Copernicus and Landsat programmes, please refer to chapter on <a href="https://fao-eostat.github.io/UN-Handbook/th_data_sources.html">Earth Observation Data Sources</a>.</p>
</section><section id="introduction-of-remote-sensing-imagery" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="introduction-of-remote-sensing-imagery">
<span class="header-section-number">4.2</span> Introduction of remote sensing imagery</h2>
<p>Remote sensing imagery refers to data collected by sensors mounted on satellite platforms, used to observe and analyze the Earth’s surface and its atmosphere from a distance. These images capture information about various phenomena and play an important role in the study of the surface of the Earth. These images are usually comprised of multiple bands and important for the study of agriculture statistics, land cover/land use and other different tasks. In agriculture statistics, remote sensing applications are based on the interaction of electromagnetic radiation with soil or plant material. The advantage of remote sensing in agriculture is its ability to provide detailed information about crop characteristics. For example, spectral, textural, phenological features can be used to create a map showing plant distribution. Indicators such as Normalized Difference Vegetation Index (NDVI), Leaf Area Index (LAI), biomass, crop density can be used to assess vegetation growth.</p>
<p>Remote sensing imagery is broadly classified into two main categories based on the type of sensors used: optical remote sensing imagery and radar remote sensing imagery. Optical sensors (e.g., cameras or imaging spectrometers) primarily capture electromagnetic radiation in spectral bands such as visible light, near-infrared, or short-wave infrared. Radar remote sensing imagery, especially in the context of Earth observation, is predominantly associated with Synthetic Aperture Radar (SAR).</p>
<p><strong>Table</strong> <strong>1 The class and applications of remote sensing</strong></p>
<div id="tbl-bands" class="anchored">
<table class="table">
<caption>Table&nbsp;4.1: Spectral bands used in remote sensing</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 25%">
<col style="width: 38%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Class</strong></td>
<td><strong>Bands</strong></td>
<td><strong>Wavelength</strong></td>
</tr>
<tr class="even">
<td>Optical</td>
<td>visible light</td>
<td>violet (0.380 - 0.450 µm)</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>blue (0.450 - 0.485 µm)</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>cyan (0.485 - 0.500 µm)</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>green (0.500 - 0.565 µm)</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>yellow (0.565 - 0.590 µm)</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>orange (0.590 - 0.625 µm)</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>red (0.625 - 0.750 µm)</td>
</tr>
<tr class="odd">
<td></td>
<td>near-infrared</td>
<td>0.750 - 1.00 µm</td>
</tr>
<tr class="even">
<td></td>
<td>short-wave infrared</td>
<td>1.0 - 3.0 µm</td>
</tr>
<tr class="odd">
<td></td>
<td>thermal</td>
<td>3 - 14.5 µm</td>
</tr>
<tr class="even">
<td>Microwave</td>
<td>SAR</td>
<td>1 mm – 1 m</td>
</tr>
</tbody>
</table>
</div>
<p>Optical remote sensing imagery makes use of visible, near-infrared and short-wave infrared sensors (passive optical sensors) to form images of the Earth’s surface by receiving the solar radiation reflected from targets on the ground. Ground objects reflect and absorb radiation differently at each wavelength. Thus, the targets can be distinguished by their spectral reflectance signatures in the remote sensing imagery. Vegetation has a unique spectral signature. This signature enables it to be distinguished readily from other types of land cover in an optical/near-infrared image. For specific crops, due to their spectral and phenological characteristics, the combination of phenological period information with multi-temporal remote sensing imagery can be used to explore a crop area and its status in the growing season.</p>
<p>Radar satellites emit its own microwave signals and analyze the returning echoes. This capability allows radar to penetrate clouds, haze, and even vegetation canopies, providing data regardless of daylight or weather conditions.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-optical-sar" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_optical_sar.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.1: Comparison of optical and SAR imagery in Taishan City, Jiangmen City, Guangdong Province, China. (a) Google high resolution imagery; (b)optical satellite image of Sentinel-2 satellite, April 23, 2025; (c) SAR satellite image of Sentinel-1 satellite, April 23, 2025.</figcaption></figure>
</div>
</div>
</div>
</section><section id="chinese-earth-observation-satellites" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="chinese-earth-observation-satellites">
<span class="header-section-number">4.3</span> Chinese Earth observation satellites</h2>
<p>Gaofen (GF, “High Resolution”) is a series of civilian Earth observation satellites developed and launched for the China High-resolution Earth Observation System (CHEOS), a state-sponsored programme aimed to develop a near-real time, all-weather, global surveillance network consisting of satellite, near-space (stratosphere) airships, and aerial observation platforms. Among these satellites, Gaofen 1 (GF-1), Gaofen 2 (GF-2), Gaofen 4 (GF-4), Gaofen 5 (GF-5), Gaofen 6 (GF-6), Gaofen 7 (GF-7) are optical satellites. They all play an important role in remote sensing for agriculture statistics.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gaofen1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_gf1.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.2: Satellite imagery of rice growth stages in Shouxian Country, Huainan City, Anhui Province, China.(a) rice distribution map (b) satellite image of GF-1 PMS, May 23, 2024 (c) satellite image of GF-1 PMS, August 11, 2024.</figcaption></figure>
</div>
</div>
</div>
<p>GF-1 and GF-6 are the Earth observation satellites operating in a 650 km Sun-Synchronous Orbit (SSO). The first GF-1 satellite was launched on April 26, 2013 and GF-6 satellite was launched on June 2, 2018. They are equipped with two high-resolution cameras and four medium-resolution wide-field cameras. The Panchromatic/Multispectral Sensor (PMS) can capture Earth imagery with a spatial resolution of 2 m in the panchromatic or black-and-white mode, and 8 m in the multispectral or color imagery. Its nominal revisit cycle is 64 days. Using its onboard pointing capabity, a specific target area can be surveyed every four days. The Wide Field View Sensor (WFV) offer a spatial resolution of 16 m and ground swath width of 800 km, allowing the satellite to collect the imagery of entire globe in only 4 days (<a href="#tbl-gaofen-1">Table&nbsp;<span>4.2</span></a>).</p>
<div id="tbl-gaofen-1" class="anchored">
<table class="table">
<caption>Table&nbsp;4.2: Sensors onboard GF-1 and GF-6 satellites</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead><tr class="header">
<th>Sensor. ensor</th>
<th>Band number</th>
<th>Spectral range</th>
<th>Spatial resol.</th>
<th>Bit Depth</th>
<th>Swath Width</th>
<th>Revisit cycle.</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Panch romatic</td>
<td>B1</td>
<td>0.45 - 0.90 µm</td>
<td>2 m</td>
<td>12 bit</td>
<td>GF-1 &gt; 60 km</td>
<td>32 days</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>GF-6 &gt; 90 km</td>
<td></td>
</tr>
<tr class="odd">
<td>Multis pectral</td>
<td>B2</td>
<td>0.45 - 0.52 µm</td>
<td>8 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B3</td>
<td>0.52 - 0.59 µm</td>
<td>8 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B4</td>
<td>0.63 - 0.69 µm</td>
<td>8 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B5</td>
<td>0.77 - 0.89 µm</td>
<td>8 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Wide Field Viewer</td>
<td>B6</td>
<td>0.45 - 0.52 µm</td>
<td>16 m</td>
<td></td>
<td>&gt; 800 km</td>
<td>4 days</td>
</tr>
<tr class="even">
<td></td>
<td>B7</td>
<td>0.52 - 0.59 µm</td>
<td>16 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B8</td>
<td>0.63 - 0.69 µm</td>
<td>16 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B9</td>
<td>0.77 - 0.89 µm</td>
<td>16 m</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gaofen6" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_gf6.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.3: GF-6 WFV image in an area of the Southern part of Goiás, Brazil (red: B9, green: B8, blue: B7).</figcaption></figure>
</div>
</div>
</div>
<p>The GF-2 satellite was launched on August 19, 2014. It was designed and developed by China Academy of Space Technology (CAST). It is capable of collecting satellite imagery with a Ground Sampling Distance (GSD) of 0.8 m panchromatic and 3.2 m multispectral bands on a swath of 45 km. GF-2 supports applications in Geographic Information System (GIS) mapping, engineering and construction, climate change, environmental monitoring, precision agriculture, disaster relief, urban planning, and many other applications. Due to its submeter spatial resolution, it is very important to precision agriculture. Its nominal revisit cycle is 64 days. Using its onboard pointing capabity, a target area can be surveyed every five days.</p>
<div id="tbl-gaofen-2" class="anchored">
<table class="table">
<caption>Table&nbsp;4.3: Sensors onboard GF-2 satellite</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead><tr class="header">
<th>Sensor</th>
<th>Band number</th>
<th>Spectral range</th>
<th>Spatial resol.</th>
<th>Bit Depth</th>
<th>Swath Width</th>
<th>Revisit cycle</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Panch</td>
<td>B1</td>
<td>0.45 -</td>
<td>0.8 m</td>
<td>10 bit</td>
<td>45 km</td>
<td>64 days</td>
</tr>
<tr class="even">
<td>Multis pectral</td>
<td>B2</td>
<td>0.45 - 0.52 µm</td>
<td>3.2 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B3</td>
<td>0.52 - 0.59 µm</td>
<td>3.2 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B4</td>
<td>0.63 - 0.69 µm</td>
<td>3.2 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B5</td>
<td>0.77 - 0.89 µm</td>
<td>3.2 m</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gaofen2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_gf2.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.4: GF-2 image in an area of Jiangmen City, Guangdong Province, China, June 9, 2025 (red: B5, green: B4, blue: B3).</figcaption></figure>
</div>
</div>
</div>
<p>GF-4 is designed for Earth observation from a geosynchronous orbit and it has different features: high spatial resolution, multiple payload types, strong maneuverability, large swath width and rapid imaging. Its first satellite was launched on December 29, 2015. GF-4 features a visible light and infrared staring optical imager with common optical system. The ground resolution for the visible light imager is 50 m and for the Mid-Wave Infrared (MWIR) payload is 400 m. This payload allows the observation of China and the surrounding areas with a high temporal resolution. GF-4 data application includes disaster monitoring, meteorological observation agriculture and so on.</p>
<div id="tbl-gaofen-4" class="anchored">
<table class="table">
<caption>Table&nbsp;4.4: Sensors onboard GF-4 satellite</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead><tr class="header">
<th>Sensor</th>
<th>Band number</th>
<th>Spectral range</th>
<th>Spatial resol.</th>
<th>Bit Depth</th>
<th>Swath Width</th>
<th>Revisit cycle</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Panch romatic</td>
<td>B1</td>
<td>0.45 - 0.90 µm</td>
<td>50 m</td>
<td>10 bit</td>
<td>400 km</td>
<td>20 seconds</td>
</tr>
<tr class="even">
<td>Multis pectral</td>
<td>B2</td>
<td>0.45 - 0.52 µm</td>
<td>50 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B3</td>
<td>0.52 - 0.59 µm</td>
<td>50 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B4</td>
<td>0.63 - 0.69 µm</td>
<td>50 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B5</td>
<td>0.76 - 0.90 µm</td>
<td>50 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B6</td>
<td>3.50 - 4.10 µm</td>
<td>400 m</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gaofen4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_gf4.jpeg" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.5: GF-4 image in an area of the Formosa Island, March 23, 2025. (a) visible light image (red: B3, green: B5, blue: B4) (b) MWIR image (B6).</figcaption></figure>
</div>
</div>
</div>
<p>The GF-5 satellite was launched on May 9, 2018. It simultaneously conduct comprehensive observations of both land and atmosphere. It is configured with six types of payloads, including Advanced Hyperspectral Imager (AHSI), Visual and Infrared Multispectral Sensor (VIMS), Greenhouse-gases Monitoring Instrument (GMI), atmospheric infrared ultraspectral (AIUS), environment monitoring instrument (EMI), directional polarization camera (DPC). GF-5 can acquire 330 spectral bands within the range from visible light to short-wave infrared (400-2500 nm).</p>
<div id="tbl-gaofen-5" class="anchored">
<table class="table">
<caption>Table&nbsp;4.5: Sensors onboard GF-5 satellite</caption>
<colgroup>
<col style="width: 18%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
</colgroup>
<thead><tr class="header">
<th>Sensor.</th>
<th>Spectral Range</th>
<th>Spectral resolution</th>
<th>Spatial resolution</th>
<th>Swath Width.</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>AHSI</td>
<td>0.40 - 2.50 µm</td>
<td>
<p>VNIR : 5 nm,</p>
<p>SWIR : 10 nm</p>
</td>
<td>30 m</td>
<td>60 km</td>
</tr>
<tr class="even">
<td>VIMS</td>
<td>0.45 - 0.52 µm</td>
<td>n/a</td>
<td>20 m</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>0.52 - 0.60 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>0.60 - 0.68 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>0.76 - 0.86 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>1.55 - 1.75 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>2.08 - 2.35 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>3.50 - 3.90 µm</td>
<td></td>
<td>40 m</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>4.85 - 5.05 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>8.01 - 8.39 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>8.42 - 8.83 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>10.30 - 11.30 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>11.40 - 12.50 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>GMI</td>
<td>0.759 - 0.769 µm</td>
<td>0.6 cm 0.27 cm</td>
<td>10.3 km</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>1.568 - 1.583 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>1.642 - 1.658 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>2.043 - 2.058 µm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>AIUS</td>
<td>750 - 4100 cm (2.4 – 13.3 µm)</td>
<td>0.03 cm</td>
<td>n/a</td>
<td></td>
</tr>
<tr class="odd">
<td>EMI</td>
<td>240 - 315 nm</td>
<td>0.3 - 0.5 nm</td>
<td>
<p>48 km</p>
<p>13 km</p>
</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>311 - 403 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>401 - 550 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>545 - 710 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>DPC</td>
<td>433 - 453 nm</td>
<td>n/a</td>
<td>3.5 km</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>480 - 500 nm (P)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>555 - 575 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>660 - 680 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>758 - 768 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>745 - 785 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>845 - 885 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>900 - 920 nm</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gaofen5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_gf5.jpeg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.6: GF-5 image in an area of the Northeastern coast of Guangdong Province, China, November 11, 2024. (a) GF-5 image (b) Point1: Surface Reflectance of crop (c) Point2: Surface Reflectance of buildings (d) Point3: Surface Reflectance of sea.</figcaption></figure>
</div>
</div>
</div>
<p>GF-7 was launched on November 3, 2019. It is an optical satellite for mapping purposes for Former National Administration of Surveying, Mapping and Geoinformation of China (NASG) similar, but improved, to the earlier ZY-3. GF-7 is China’s first civilian sub-meter resolution optical stereo mapping satellite and it features two camera systems for mapping and surveying and a laser altimeter so that it is capable of acquiring high spatial resolution optical stereo observation data and high-precision laser altimetry data.</p>
<div id="tbl-gaofen-7" class="anchored">
<table class="table">
<caption>Table&nbsp;4.6: Sensors onboard GF-7 satellite</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead><tr class="header">
<th>Sensor</th>
<th>Band number</th>
<th>Spectral range</th>
<th>Spatial resol.</th>
<th>Bit Depth</th>
<th>Swath Width</th>
<th>Revisit cycle</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Panch romatic</td>
<td>B1</td>
<td>0.45 - 0.90 µm</td>
<td>0.8</td>
<td>11 bit</td>
<td>200 km</td>
<td>60 days</td>
</tr>
<tr class="even">
<td>Multis pectral</td>
<td>B2</td>
<td>0.45 - 0.52 µm</td>
<td>2.6 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B3</td>
<td>0.52 - 0.59 µm</td>
<td>2.6 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>B4</td>
<td>0.63 - 0.69 µm</td>
<td>2.6 m</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>B5</td>
<td>0.76 - 0.89 µm</td>
<td>2.6 m</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>All GF optical remote sensing imagery can be purchased and downloaded on the website of <a href="https://data.cresda.cn/#/2dMap">China Center For Resources Satellite Data And Application</a>. GF-1 WFV, GF-4, GF-6 WFV are free. After signing up, the data can be downloaded directly without limits. GF-1 PMS、GF-2 PMS、GF-5 and GF-6 PMS require payment.</p>
<p>Among the GF series of satellites, GF-3 is specifically designed as a radar remote sensing. GF-3 was launched on August 10, 2016. It is the first civilian C-band fully polarimetric Synthetic Aperture Radar (SAR) imaging satellite of China National Space Administration (CNSA), equipped with a multi-polarized C-band SAR at meter-level resolution. GF-3’s SAR package can operate in 12 different working modes, from high-resolution (1 m) to large-swath (650 km), and operate in all-weather, day/night conditions.</p>
<div id="tbl-gaofen-3" class="anchored">
<table class="table">
<caption>Table&nbsp;4.7: Sensors onboard GF-3 SAR satellite</caption>
<colgroup>
<col style="width: 29%">
<col style="width: 19%">
<col style="width: 15%">
<col style="width: 16%">
<col style="width: 14%">
</colgroup>
<thead><tr class="header">
<th>Observing Mode</th>
<th>Polarization</th>
<th>Incidence angle</th>
<th>Resolution</th>
<th>Swath</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Spotlight</td>
<td>single</td>
<td>20~50°</td>
<td>1m</td>
<td>10 km</td>
</tr>
<tr class="even">
<td>Ultra-fine stripmap</td>
<td>dual</td>
<td>20~50°</td>
<td>3m</td>
<td>30 km</td>
</tr>
<tr class="odd">
<td>Fine stripmap</td>
<td>dual</td>
<td>19~50°</td>
<td>5m</td>
<td>50 km</td>
</tr>
<tr class="even">
<td>Wide fine stripmap</td>
<td>dual.</td>
<td>19~50°</td>
<td>10m</td>
<td>100 km</td>
</tr>
<tr class="odd">
<td>Standard stripmap</td>
<td>dual.</td>
<td>17~50°</td>
<td>25m</td>
<td>250 km</td>
</tr>
<tr class="even">
<td>Narrow ScanSAR</td>
<td>dual</td>
<td>17~50°</td>
<td>50m</td>
<td>300 km</td>
</tr>
<tr class="odd">
<td>Wide ScanSAR</td>
<td>dual</td>
<td>17~50°</td>
<td>100m</td>
<td>500 km</td>
</tr>
<tr class="even">
<td>Global observation</td>
<td>dual</td>
<td>17~50°</td>
<td>500m</td>
<td>650 km</td>
</tr>
<tr class="odd">
<td>Quad-pol stripmap</td>
<td>quad</td>
<td>20~41°</td>
<td>8m</td>
<td>30 km</td>
</tr>
<tr class="even">
<td>Wide quad-pol</td>
<td>quad</td>
<td>20~38°</td>
<td>25m</td>
<td>40 km</td>
</tr>
<tr class="odd">
<td>Wave</td>
<td>quad</td>
<td>20~41°</td>
<td>10m</td>
<td>5 km</td>
</tr>
<tr class="even">
<td>Exp incidence angle</td>
<td>dual</td>
<td>10~20°</td>
<td>25m</td>
<td>130 km</td>
</tr>
<tr class="odd">
<td></td>
<td>dual</td>
<td>50~60°</td>
<td>25m</td>
<td>80 km</td>
</tr>
</tbody>
</table>
</div>
<p>All the GF-3 SAR remote sensing imagery requires payment and can be purchased on the website of <a href="https://data.cresda.cn/#/2dMap">China Center For Resources Satellite Data and Applications</a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gaofen3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_gf3.jpeg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.7: GF-3 fine stripmap image in an area of Jiangmen City, Guangdong Province, China, April 18, 2025: (a) HH: Horizontal-Horizontal (b) HV: Horizontal-Vertical polarizations.</figcaption></figure>
</div>
</div>
</div>
</section><section id="landsat-programme" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="landsat-programme">
<span class="header-section-number">4.4</span> Landsat programme</h2>
<p>The Landsat program consists of a series of Earth-observing satellite missions jointly managed by National Aeronautics and Space Administration (NASA) and the U.S. Geological Survey (USGS). Landsat-9 is the latest satellite in the Landsat series. It was launched in September 27, 2021. Landsat-9 carries two science instruments including the Operational Land Imager2(OLI-2) and Thermal Infrared Sensor2(TIRS-2) and enables informed decision support for many key areas.</p>
<div id="tbl-landsat-9" class="anchored">
<table class="table">
<caption>Table&nbsp;4.8: Sensors onboard Landsat-9 satellite</caption>
<colgroup>
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 18%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 17%">
</colgroup>
<thead><tr class="header">
<th>Sensor</th>
<th>Band number</th>
<th>Spectral range</th>
<th>Spatial resol.</th>
<th>Bit Depth</th>
<th>Swath Width</th>
<th>Revisit cycle</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>OLI-2</td>
<td>B1</td>
<td>0.43 - 0.45 µm</td>
<td>30 m</td>
<td>16 bit</td>
<td>185 km</td>
<td>16 days</td>
<td>Coastal aerosol</td>
</tr>
<tr class="even">
<td></td>
<td>B2</td>
<td>0.45 - 0.51 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Blue</td>
</tr>
<tr class="odd">
<td></td>
<td>B3</td>
<td>0.53 - 0.59 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Green</td>
</tr>
<tr class="even">
<td></td>
<td>B4</td>
<td>0.64 - 0.67 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Red</td>
</tr>
<tr class="odd">
<td></td>
<td>B5</td>
<td>0.85 - 0.88 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Near infrared</td>
</tr>
<tr class="even">
<td></td>
<td>B6</td>
<td>1.57 - 1.65 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Shortwave IR 1</td>
</tr>
<tr class="odd">
<td></td>
<td>B7</td>
<td>2.11 - 2.29 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Shortwave IR 2</td>
</tr>
<tr class="even">
<td></td>
<td>B8</td>
<td>0.52 - 0.90 µm</td>
<td>15 m</td>
<td></td>
<td></td>
<td></td>
<td>Panchromatic</td>
</tr>
<tr class="odd">
<td></td>
<td>B9</td>
<td>1.36 - 1.38 µm</td>
<td>100 m</td>
<td></td>
<td></td>
<td></td>
<td>Cirrus</td>
</tr>
<tr class="even">
<td>TIRS-2</td>
<td>B10</td>
<td>10.60 - 11.19 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Thermal IR 1</td>
</tr>
<tr class="odd">
<td></td>
<td>B11</td>
<td>11.50 - 12.51 µm</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Thermal IR 2</td>
</tr>
</tbody>
</table>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-landsat9" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_landsat.jpeg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.8: Landsat-9 image in an area of the Northeastern Colorado, USA, June 15, 2025 (red: B7, green: B5, blue: B3)</figcaption></figure>
</div>
</div>
</div>
<p>Landsat imagery can be downloaded for free from the <a href="https://earthexplorer.usgs.gov">USGS Earth Explorer</a> or from cloud providers such as <a href="https://planetarycomputer.microsoft.com/">Microsoft Planetary Computer</a>. Please refer to the chapter <a href="https://fao-eostat.github.io/UN-Handbook/th_data_sources.html">Earth observation big data sources</a> for a description of how to access remote sensing data in cloud collections.</p>
</section><section id="copernicus-programme" class="level2" data-number="4.5"><h2 data-number="4.5" class="anchored" data-anchor-id="copernicus-programme">
<span class="header-section-number">4.5</span> Copernicus Programme</h2>
<p>The Copernicus Programme is headed by the European Commission in partnership with the European Space Agency (ESA) that implements a constellation of satellites called Sentinels. These satellites include all-weather radar images from Sentinel-1A and 1B, high-resolution optical images from Sentinel-2A and 2B, ocean and land data suitable for environmental and climate monitoring from Sentinel-3, as well as air quality data from Sentinel-5P.</p>
<section id="sentinel-1-mission" class="level3" data-number="4.5.1"><h3 data-number="4.5.1" class="anchored" data-anchor-id="sentinel-1-mission">
<span class="header-section-number">4.5.1</span> Sentinel-1 mission</h3>
<p>The Sentinel-1 mission, operated by the European Space Agency (ESA), consists of a constellation of C-band Synthetic Aperture Radar (SAR) satellites designed to provide continuous, all-weather, day-and-night Earth observation capabilities. Operating at a central frequency of approximately 5.405 GHz, corresponding to a wavelength of 5.6 cm, the system offers multiple polarization configurations, including single-polarization modes (HH or VV) and dual-polarization modes (HH+HV or VV+VH). These options allow for flexibility in addressing diverse application requirements, ranging from high-resolution terrestrial monitoring to large-area maritime surveillance.</p>
<p>Sentinel-1 supports four primary imaging modes, each optimized to balance spatial resolution, swath width, and revisit frequency according to the observational context. The Stripmap (SM) mode provides a swath width of approximately 80 km at a spatial resolution of about 5 m in both range and azimuth directions, making it suitable for applications demanding fine spatial detail over relatively narrow swaths, such as scientific investigations and precision mapping. The Interferometric Wide Swath (IW) mode, which constitutes the default operational mode over land, achieves a swath width of roughly 250 km and a spatial resolution of about 5 m (range) by 20 m (azimuth). This mode employs the Terrain Observation by Progressive Scans (TOPS) technique, enabling high interferometric coherence and reduced azimuth scalloping, thereby supporting deformation monitoring, land-cover mapping, and interferometric SAR (InSAR) applications.</p>
<p>The Extra-Wide Swath (EW) mode, predominantly employed for maritime and cryospheric applications, covers a swath of approximately 400 km with a spatial resolution of 20 m (range) by 40 m (azimuth). Its wide coverage facilitates large-scale change detection, sea-ice monitoring, and vessel tracking. Finally, the Wave (WV) mode acquires small image segments, or imagettes, of 20 km swath width at intervals of approximately 100 km along the satellite ground track, with a spatial resolution of about 5 m × 5 m. This mode is specifically designed for the retrieval of ocean wave spectra and sea state parameters.</p>
<p>In summary, the Sentinel-1 mission offers a set of operational modes that balance resolution and coverage to meet the diverse observational requirements of land, ocean, and ice monitoring. Its flexible polarization schemes and consistent revisit capabilities make it a cornerstone in global SAR-based Earth observation programs.</p>
<div id="tbl-sentinel-1" class="anchored">
<table class="table">
<caption>Table&nbsp;4.9: Operational modes for Sentinel-1 satellites</caption>
<colgroup>
<col style="width: 4%">
<col style="width: 17%">
<col style="width: 17%">
<col style="width: 45%">
<col style="width: 14%">
</colgroup>
<thead><tr class="header">
<th>Mode</th>
<th>Swath (km)</th>
<th>Resolution (m)</th>
<th>Typical Use</th>
<th>Polarization</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>SM</td>
<td>80</td>
<td>5 × 5</td>
<td>Detailed mapping, science</td>
<td>Single/Dual</td>
</tr>
<tr class="even">
<td>IW</td>
<td>250</td>
<td>5 × 20</td>
<td>Land, InSAR, deformation</td>
<td>Single/Dual</td>
</tr>
<tr class="odd">
<td>EW</td>
<td>400</td>
<td>20 × 40</td>
<td>Maritime, sea ice, large-scale change</td>
<td>Single/Dual</td>
</tr>
<tr class="even">
<td>WV</td>
<td>20 (imagettes)</td>
<td>5 × 5</td>
<td>Ocean waves, sea state</td>
<td>Single</td>
</tr>
</tbody>
</table>
</div>
<p>Sentinel-1 products are openly available from cloud providers such as <a href="https://dataspace.copernicus.eu/">Copernicus Data Space Ecosystem</a> and <a href="https://planetarycomputer.microsoft.com/">Microsoft Planetary Computer</a>. Please refer to the chapter <a href="https://fao-eostat.github.io/UN-Handbook/th_data_sources.html">Earth observation big data sources</a> for a description of how to access remote sensing data in cloud collections.</p>
</section><section id="sentinel-2-mission" class="level3" data-number="4.5.2"><h3 data-number="4.5.2" class="anchored" data-anchor-id="sentinel-2-mission">
<span class="header-section-number">4.5.2</span> Sentinel-2 mission</h3>
<p>The Sentinel-2 mission, developed under the European Union’s Copernicus Programme and operated by the European Space Agency (ESA), consists of a constellation of polar-orbiting satellites, Sentinel-2A (launched in June 2015), Sentinel-2B (launched in March 2017), and Sentinel-2C (launched in September 2024). The Sentinel-2 satellites are equipped with the MultiSpectral Instrument (MSI), a push-broom imaging sensor that acquires data in 13 discrete spectral bands spanning the visible, near-infrared (NIR), and shortwave infrared (SWIR) regions of the electromagnetic spectrum. The MSI is designed to provide high spatial resolution (10 m, 20 m, or 60 m depending on the spectral band) over a swath width of 290 km, enabling systematic coverage of terrestrial and coastal ecosystems.</p>
<p>The mission supports a broad range of applications, including vegetation monitoring, agricultural management, forestry assessment, inland and coastal water quality mapping, disaster risk reduction, and land use/land cover classification. The Sentinel-2 satellites are the first civil optical Earth observation mission of its kind to include three bands in the ‘red edge’, which provides key information on the vegetation state. Sentinel-2 satellite will be able to see very early changes in plant health due to its high temporal, spatial resolution, and 3 red edge bands. This is particularly useful for the end-users and policymakers for agriculture applications and to detect early signs of food shortages in different places.</p>
<div id="tbl-sentinel-2" class="anchored">
<table class="table">
<caption>Table&nbsp;4.10: Description of MSI sensor onboard Sentinel-2 satellites</caption>
<colgroup>
<col style="width: 4%">
<col style="width: 12%">
<col style="width: 15%">
<col style="width: 9%">
<col style="width: 14%">
<col style="width: 42%">
</colgroup>
<thead><tr class="header">
<th>Band</th>
<th>Name</th>
<th>Central Wavelength (nm)</th>
<th>Bandwidth (nm)</th>
<th>Spatial Resolution (m)</th>
<th>Primary Applications</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>B1</td>
<td>Coastal aerosol</td>
<td>443</td>
<td>20</td>
<td>60</td>
<td>Aerosol studies, coastal and atmospheric correction</td>
</tr>
<tr class="even">
<td>B2</td>
<td>Blue</td>
<td>490</td>
<td>65</td>
<td>10</td>
<td>Bathymetry, vegetation, and soil discrimination</td>
</tr>
<tr class="odd">
<td>B3</td>
<td>Green</td>
<td>560</td>
<td>35</td>
<td>10</td>
<td>Vegetation vigor, biomass estimation</td>
</tr>
<tr class="even">
<td>B4</td>
<td>Red</td>
<td>665</td>
<td>30</td>
<td>10</td>
<td>Vegetation monitoring, soil-vegetation discrimination</td>
</tr>
<tr class="odd">
<td>B5</td>
<td>Red Edge 1</td>
<td>705</td>
<td>15</td>
<td>20</td>
<td>Chlorophyll estimation, vegetation stress detection</td>
</tr>
<tr class="even">
<td>B6</td>
<td>Red Edge 2</td>
<td>740</td>
<td>15</td>
<td>20</td>
<td>Vegetation classification, canopy structure</td>
</tr>
<tr class="odd">
<td>B7</td>
<td>Red Edge 3</td>
<td>783</td>
<td>20</td>
<td>20</td>
<td>Leaf area index, vegetation biophysical parameters</td>
</tr>
<tr class="even">
<td>B8</td>
<td>Near Infrared (NIR)</td>
<td>842</td>
<td>115</td>
<td>10</td>
<td>Biomass, water body delineation, vegetation vigor</td>
</tr>
<tr class="odd">
<td>B8A</td>
<td>Narrow NIR</td>
<td>865</td>
<td>20</td>
<td>20</td>
<td>Canopy chlorophyll content, vegetation structure</td>
</tr>
<tr class="even">
<td>B9</td>
<td>Water vapour</td>
<td>945</td>
<td>20</td>
<td>60</td>
<td>Atmospheric water vapour retrieval</td>
</tr>
<tr class="odd">
<td>B10</td>
<td>SWIR – Cirrus</td>
<td>1375</td>
<td>30</td>
<td>60</td>
<td>Cirrus cloud detection</td>
</tr>
<tr class="even">
<td>B11</td>
<td>SWIR 1</td>
<td>1610</td>
<td>90</td>
<td>20</td>
<td>Vegetation moisture, burned area mapping</td>
</tr>
<tr class="odd">
<td>B12</td>
<td>SWIR 2</td>
<td>2190</td>
<td>180</td>
<td>20</td>
<td>Soil composition, snow/ice discrimination, vegetation moisture</td>
</tr>
</tbody>
</table>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-s2-rondonia" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./images/th_remote_sensing/image_s2_rondonia.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4.9: Sentinel-2 image in an area of Rondonia, Brazil, September 16, 2022 (red: B11, green: B8A, blue: B4)</figcaption></figure>
</div>
</div>
</div>
<p>Sentinel-2 products are openly available from cloud providers such as <a href="https://dataspace.copernicus.eu/">Copernicus Data Space Ecosystem</a>, <a href="https://aws.amazon.com/earth/">Amazon Web Services</a> and <a href="https://planetarycomputer.microsoft.com/">Microsoft Planetary Computer</a>. Please refer to the chapter <a href="https://fao-eostat.github.io/UN-Handbook/th_data_sources.html">Earth observation big data sources</a> for a description of how to access remote sensing data in cloud collections.</p>
</section></section><section id="final-remarks" class="level2" data-number="4.6"><h2 data-number="4.6" class="anchored" data-anchor-id="final-remarks">
<span class="header-section-number">4.6</span> Final remarks</h2>
<p>Multi-source satellite remote sensing facilitates coordinated global observation through orbital synergy, while the integration of optical imagery and SAR datasets enables multisensor data collection across heterogeneous meteorological regimes. This synergistic complementarity between spectral resolution and all-weather capability holds significant implications for enhancing the spatiotemporal continuity and operational robustness of agricultural statistical monitoring systems.</p>


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./theory.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Foundations</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./th_data_sources.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Earth observation big data sources</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">Edited by Gilberto Camara, Lorenzo de Simone and Ronald Jansen.</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This book was built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>


</body></html>